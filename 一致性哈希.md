# 一致性哈希

> **一致性哈希**主要解决的问题是数据存储应用一般哈希算法，带来的rehash代价问题

一个被水平拆分的表，很多数据需要按照一定的存放**规则**被放到不同的服务器中。查找时根据**存放时的规则**去找存放的数据。

## 一般哈希带来的问题

这里的存放规则可以是哈希的方式。

例如HashMap通过计算key的哈希值，用这个哈希值对桶的总数取模运算，即可得到桶的下标位。在查找某个key对应的数据时，仍然计算该key对应的哈希值，找到相应的桶，再由此开始找数据。

如果采用类似这种方式进行表数据的哈希，一般情况下没有问题。但一旦数据量进一步扩大，当我们需要增加服务器时，就需要进行rehash，这个代价是很大的。

## 一致性哈希

因此我们需要有一种算法，当增加、删除数据服务器时，对于大多数记录k-v，需要尽可能保证其分配到与原来相同的节点上，减少数据迁移的代价。

### 算法详解

一致性hash实际上也是hash，但可以理解为对**数据区间的哈希**。

<img src="/Users/liuwenshuo/Documents/Notes/Daily_study/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzOTQ1MjQ2,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述" style="zoom: 50%;" />

一致性哈希将整个哈希空间组织成一个虚拟的圆环，即哈希函数的值域为0-2^32-1（32位无符号整形），这个环称为哈希环。

先将我们的节点（服务器）按照一定的规则（例如ip地址的哈希值）进行哈希，对2^32取模，得到哈希值，使节点落在环上。

例如现在有四台机器，那么就得到了这样的环：

<img src="https://img-blog.csdnimg.cn/20200326111558674.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzOTQ1MjQ2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

当一个数据过来，可以得到该数据的key的哈希值，一定落在该环的某个位置。然后规则是：**如果恰好落在了机器的节点上，就直接存放在该机器；否则顺时针寻找下一台机器进行数据存储。**如下图所示，A、B、C、D、E均为数据，可以看到其算法规则：

<img src="/Users/liuwenshuo/Documents/Notes/Daily_study/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzOTQ1MjQ2,size_16,color_FFFFFF,t_70-20220511154442886.png" alt="在这里插入图片描述" style="zoom:50%;" />

### 为什么可以解决rehash问题

1. 假设此时某个服务器节点（D2）宕机了

可以看到只有数据A的记录需要rehash到D1节点，其他数据无影响。即只有D0-D2之间的数据记录需要rehash到D1。

<img src="https://img-blog.csdnimg.cn/2020032611163587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzOTQ1MjQ2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

2. 假设此时增加了一个新的服务器节点（D4）

可以看到只有D2-D4之间的数据需要rehash到D4，其他数据不需改变。

<img src="/Users/liuwenshuo/Documents/Notes/Daily_study/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzOTQ1MjQ2,size_16,color_FFFFFF,t_70-20220511154913455.png" alt="在这里插入图片描述" style="zoom:50%;" />

### 带来的问题及解决方案

**数据倾斜问题**：当服务器节点数较少时，节点间可能分布不均，导致数据倾斜，即大部分的数据都集中缓存到某一台服务器中。例如如图所示，D0节点承载了绝大多数的数据存储。

<img src="/Users/liuwenshuo/Documents/Notes/Daily_study/数据倾斜.png" alt="在这里插入图片描述" style="zoom:50%;" />

**解决**：一致性哈希引入了虚拟节点的机制。每个机器节点会进行多次哈希，最终每台机器在环上会有多个虚拟节点存在，这就大大削弱并避免了数据倾斜问题。例如下图中D1通过多次哈希生成了三个虚拟节点。实际上虚拟节点数通常设置为32以上，使得较少的服务节点也能做到相对均匀的哈希数据分布。

<img src="/Users/liuwenshuo/Documents/Notes/Daily_study/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzOTQ1MjQ2,size_16,color_FFFFFF,t_70-20220511155657732.png" alt="在这里插入图片描述" style="zoom:50%;" />

## 应用场景

一致性哈希常被用于负载均衡。例如Dubbo的负载均衡机制中有一种策略是一致性哈希，使用虚拟节点实现；Redis集群分槽也使用了这种思想；数据的水平切分等等。
